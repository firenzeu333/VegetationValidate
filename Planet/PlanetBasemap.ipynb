{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by importing all the stuff we need (be ready - the list is long...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import shutil\n",
    "from datetime import datetime \n",
    "import time\n",
    "from dateutil import parser\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import re\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util import Retry\n",
    "\n",
    "from itertools import product\n",
    "import rasterio as rio\n",
    "from rasterio import windows\n",
    "import rasterio.features\n",
    "import rasterio.warp\n",
    "\n",
    "import analona\n",
    "from dateutil import parser\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'd like to set up functions for accesing the mosaic API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mosaic_url = \"https://api.planet.com/basemaps/v1/mosaics/\"\n",
    "planet_api_key = '-paste-here-'\n",
    "\n",
    "# Init the session object\n",
    "session = requests.Session()\n",
    "retry = Retry(connect=3, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "session.auth = (planet_api_key, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the set up the mongo client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mongo_uri = ''\n",
    "client = pymongo.MongoClient(mongo_uri)\n",
    "db = client.louvre\n",
    "buildings_collection = db.buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing so it's finally time to get to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to write a function which - given a raster of building indentifications, turns each building in the raster into a geojson representation which we then add to an item we can varify and push into Louvre.\n",
    "<br>The problem arise with converting the raster to a geojson - the raster as is is just too big for a computer to process and extract all the buildings in it. Because of that we split each tiff file we get into tiles of size 256x256 and then extract the items from each of the tiles.\n",
    "<br>The raster buildings are either in the Green mask of an RGB raster, or in the White mask of a BW raster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we will do then is to write a code which splits the image into subtiles, we will use *rio* package to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tiles(ds, width=256, height=256):\n",
    "    nols, nrows = ds.meta['width'], ds.meta['height']\n",
    "    offsets = product(range(0, nols, width), range(0, nrows, height))\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "    for col_off, row_off in  offsets:\n",
    "        window = windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
    "        transform = windows.transform(window, ds.transform)\n",
    "        yield window, transform\n",
    "        \n",
    "\n",
    "def split_file(filepath):\n",
    "    folder = 'tmp_for_{}'.format(filepath.split('/')[1])\n",
    "    if os.path.exists(folder):\n",
    "        print(\"already split {}\".format(filepath.split('/')[1]))\n",
    "        return\n",
    "    \n",
    "    os.mkdir(folder)\n",
    "    with rio.open(filepath) as inds:\n",
    "        meta = inds.meta.copy()\n",
    "        for window, transform in get_tiles(inds):\n",
    "            meta['transform'] = transform\n",
    "            meta['width'], meta['height'] = window.width, window.height\n",
    "            outpath = os.path.join(folder,'{}_{}'.format(int(window.col_off), int(window.row_off)))\n",
    "            with rio.open(outpath, 'w', **meta) as outds:\n",
    "                outds.write(inds.read(window=window))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after doing so we can write a function which takes a filepath which leads to a raster, the start and end date of the mosaic, and the download url, and construct and pushes an item to Louvre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def turn_to_json(filepath, mosaic_start_date, mosaic_end_date, url):\n",
    "    folder = 'tmp_for_{}'.format(filepath.split('/')[1])\n",
    "    \n",
    "    #The first thing we do is split the original file\n",
    "    split_file(filepath)\n",
    "    \n",
    "    #Now the folder should contain all splited tiles.\n",
    "    for _, _, files in os.walk(folder):  \n",
    "        for filename in files:\n",
    "            file_route = os.path.join(folder, filename)\n",
    "            with rio.open(file_route) as dataset:\n",
    "                _, _, image_id = filepath.split('/')\n",
    "                image_id = image_id.split('.')[0]\n",
    "                \n",
    "                # Init a counter for different IDs\n",
    "                counter = 0\n",
    "                # RGB Raster\n",
    "                if(dataset.count == 4):\n",
    "                    # Read the dataset's valid data mask as a ndarray.\n",
    "                    mask = dataset.read(3)\n",
    "                # BW Raster\n",
    "                elif(dataset.count == 2):\n",
    "                    mask = dataset.read(1)\n",
    "                    \n",
    "                shp = rio.features.shapes(\n",
    "                        mask, transform=dataset.transform)\n",
    "                # Extract feature shapes and values from the array.\n",
    "                for geom, _ in shp:\n",
    "                    item = {}\n",
    "                    \n",
    "                    # Transform shapes from the dataset's own coordinate\n",
    "                    # reference system to CRS84 (EPSG:4326).\n",
    "                    geom = rio.warp.transform_geom(\n",
    "                        dataset.crs, 'EPSG:4326', geom, precision=6)\n",
    "\n",
    "                    item['_id'] = 'planet_building_{}_{}_{}'.format(image_id, filename, counter)\n",
    "                    item['geometry'] = geom\n",
    "                    item['company'] = 'Planet'\n",
    "                    item['analyticsDeliveryTime'] = {\n",
    "                        'start': datetime.utcfromtimestamp(int(round(mosaic_start_date.timestamp()))),\n",
    "                        'end': datetime.utcfromtimestamp(int(round(mosaic_end_date.timestamp())))\n",
    "                    }\n",
    "                    item['analyticsInfo'] = {\n",
    "                        'url': url,\n",
    "                        'storage': 'Planet'\n",
    "                    }\n",
    "                    item['sourceImagesIds'] = [image_id]\n",
    "                    is_valid = analona.Building(item).validate()\n",
    "                    counter += 1\n",
    "                    if(is_valid == True):\n",
    "                        buildings_collection.update({ '_id': item['_id'] }, item, upsert = True)\n",
    "                        print('pushed to db:', item['_id'])\n",
    "                    else:\n",
    "                        print('did not pass varification- {}'.format(is_valid))\n",
    "    #Remove the folder of tiles\n",
    "    shutil.rmtree(folder)\n",
    "    #Remove the image because we don't need it anymore\n",
    "    os.remove(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what we need to do is to modify the download code (originally from 'https://github.com/nsplt/planet_downloader/blob/master/basemap.py'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_quad(mosaic_name, mosaic_start_date, mosaic_end_date, quad):\n",
    "    directory = ''\n",
    "    url = quad['_links']['download']\n",
    "    if(url):\n",
    "        directory = '{}/{}'.format(str(download_directory),\\\n",
    "                                    str(mosaic_name))\n",
    "\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        res = session.get(url, stream = True)\n",
    "\n",
    "        if res.status_code != 200:\n",
    "            raise Exception('Error while getting quads: ' + res.text)\n",
    "\n",
    "        filename = str(re.findall('filename=(.+)', str(res.headers.get('Content-Disposition')))[0])\n",
    "\n",
    "        filepath = '{}/{}'.format(str(directory), filename)\n",
    "\n",
    "        print('downloading to:', filepath)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            for chunk in res.iter_content(chunk_size = 1024 * 1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "        #After we download the file locally, we can transform it and insert to louvre\n",
    "        turn_to_json(filepath, mosaic_start_date, mosaic_end_date, url)        \n",
    "    else:\n",
    "        print('no available download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_quads_batch(mosaic_name, mosaic_start_date, mosaic_end_date, quad):\n",
    "    quad_items = quad['items']\n",
    "    for item in quad_items:        \n",
    "        download_quad(mosaic_name, mosaic_start_date, mosaic_end_date, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_quads(mosaic_name, mosaic_start_date, mosaic_end_date, quad_items):\n",
    "    handle_quads_batch(mosaic_name, mosaic_start_date, mosaic_end_date, quad_items)\n",
    "    next_url = quad_items['_links'].get('_next')\n",
    "\n",
    "    if next_url:\n",
    "        next = session.get(next_url).json()\n",
    "        fetch_quads(mosaic_name, mosaic_start_date, mosaic_end_date, next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_overlap(start1, start2, end1, end2):\n",
    "    return max(start1, start2) <= min(end1, end2)\n",
    "\n",
    "def overlap_bbox(lx1, lx2, ly1, ly2, ux1, ux2, uy1, uy2):\n",
    "    x_left = max(lx1, lx2)\n",
    "    y_bottom = max(ly1, ly2)\n",
    "    x_right = min(ux1, ux2)\n",
    "    y_top = min(uy1, uy2)\n",
    "\n",
    "    if(x_left > x_right or y_bottom > y_top):\n",
    "        return False\n",
    "    else:\n",
    "        bbox = [x_left, y_bottom, x_right, y_top]\n",
    "        return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_mosaic(mosaic):\n",
    "    mosaic_id = mosaic['id']\n",
    "    print('Mosaic Name', mosaic['name'])\n",
    "    mosaic_start_date = datetime.strptime(mosaic['first_acquired'].split('T')[0], '%Y-%m-%d')\n",
    "    mosaic_end_date =  datetime.strptime(mosaic['last_acquired'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "    if(is_overlap(mosaic_start_date, start_date, mosaic_end_date, end_date)):\n",
    "        mosaic_bbox = mosaic['bbox']\n",
    "\n",
    "        overlap = overlap_bbox(mosaic_bbox[0], bbox[0], mosaic_bbox[1], bbox[1], mosaic_bbox[2], bbox[2], mosaic_bbox[3], bbox[3])\n",
    "\n",
    "        if(overlap is False):\n",
    "            print('There is no overlap between the mosaic and the bbox.')\n",
    "        else:\n",
    "            bbox_str = str(overlap[0]) + ',' + str(overlap[1]) + ',' + str(overlap[2]) + ',' + str(overlap[3])\n",
    "            quads = mosaic_url + mosaic_id + '/quads?bbox=' + bbox_str  \n",
    "            quads_res = session.get(quads).json()\n",
    "            fetch_quads(mosaic['name'], mosaic_start_date, mosaic_end_date, quads_res)\n",
    "    else:\n",
    "        print('There is no overlap between the dates.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can run the code with a bounding box and dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download_directory = '.'\n",
    "basemap_types = ['buildings']\n",
    "start_date = datetime.strptime(\"2016-09-01T06:11:00.000Z\".split('T')[0], \"%Y-%m-%d\") \n",
    "end_date = datetime.strptime(\"2018-11-01T06:11:00.000Z\".split('T')[0], \"%Y-%m-%d\") \n",
    "bbox = [35.89233398437499, 32.68099643258195, 36.37573242187499, 33.169743600216165]\n",
    "\n",
    "mosaics = session.get(mosaic_url).json()\n",
    "mosaics_list = mosaics['mosaics']\n",
    "\n",
    "for mosaic in mosaics_list:\n",
    "    mosaic_name = mosaic['name']\n",
    "    should_download = any(mosaic_name.find(type) != -1 for type in basemap_types)\n",
    "\n",
    "    if should_download:\n",
    "        download_mosaic(mosaic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
